{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74519aa9-1575-470e-af96-83e69b98ef54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import (udf, col)\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "spark = SparkSession.builder.appName(\"censo\").getOrCreate()\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85345474-e475-4829-b948-fe35aae41b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prefix_in_columns(df, prefix):\n",
    "    return df.select([col(column).alias(f\"{prefix}_{column}\") for column in df.columns])\n",
    "\n",
    "def load_json(name, bucket):\n",
    "    bucket = storage.Client().get_bucket(bucket)\n",
    "    blob = bucket.blob(f'aux/{name}.json')\n",
    "    maps = json.loads(blob.download_as_string())\n",
    "    return maps\n",
    "\n",
    "\n",
    "def mapping(df, map_, column, type_return):\n",
    "    map_func = udf(lambda key: map_.get(str(key)), type_return())\n",
    "    df = df.withColumn(column, map_func(col(column)))\n",
    "    return df\n",
    "\n",
    "def string_to_date(df, column, year):\n",
    "    if year > 2014:\n",
    "        pattern = '%d/%m/%Y'\n",
    "    else:\n",
    "        pattern = \"%d%b%Y:%H:%M:%S\"\n",
    "    map_func =  udf (lambda date: datetime.strptime(date, pattern) \n",
    "                     if type(date) == str \n",
    "                     else None, DateType())\n",
    "    df = df.withColumn(column, map_func(col(column)))\n",
    "    return df\n",
    "\n",
    "def load_csv(file, bucket, year, region=None):\n",
    "    schema = load_json(f\"schemas/{file}_schema\", bucket)\n",
    "    try:\n",
    "        schema = StructType.fromJson(schema)\n",
    "    except:\n",
    "        schema = StructType.fromJson(json.loads(schema))\n",
    "\n",
    "    if file == \"matricula\":\n",
    "        file = f\"gs://{bucket}/landing_zone/censo-escolar/{year}/matricula_{region}.csv\"\n",
    "    else:\n",
    "        file = f\"gs://{bucket}/landing_zone/censo-escolar/{year}/{file}.csv\"\n",
    "\n",
    "    df = spark \\\n",
    "            .read \\\n",
    "            .options(header=True, delimiter=\"|\", encoding=\"utf8\") \\\n",
    "            .schema(schema=schema) \\\n",
    "            .csv(file)\n",
    "    return df\n",
    "\n",
    "def transform_string_columns(df, file, bucket):\n",
    "    maps = load_json(\"maps\", bucket)\n",
    "    string_columns = [column for column in df.columns \n",
    "                      if column.startswith(\"TP\") or column.startswith(\"CO\")]\n",
    "\n",
    "    for column in string_columns:\n",
    "        if column in maps:\n",
    "            df = mapping(df, maps[column], column, StringType)\n",
    "            \n",
    "    return df\n",
    "\n",
    "def transform_boolean_columns(df):\n",
    "    boolean_columns = [column for column in df.columns \n",
    "                  if column.startswith(\"IN\")]\n",
    "\n",
    "    mapping_bool = {\n",
    "        \"0\": False,\n",
    "        \"1\": True\n",
    "    }\n",
    "\n",
    "    for column in boolean_columns:\n",
    "        df = mapping(df, mapping_bool, column, BooleanType)\n",
    "        \n",
    "    return df\n",
    "        \n",
    "def transform_integer_columns(df):\n",
    "    integer_columns = [column for column in df.columns \n",
    "                      if column.startswith(\"NU\") or column.startswith(\"QT\")]\n",
    "    for column in integer_columns:\n",
    "        df = df.withColumn(column, col(column).cast(IntegerType()))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def transform_date_columns(df, file):\n",
    "    if file == \"escolas\":\n",
    "        df = string_to_date(df, \"DT_ANO_LETIVO_INICIO\", YEAR)\n",
    "        df = string_to_date(df, \"DT_ANO_LETIVO_TERMINO\", YEAR)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def drop_columns(df, file):\n",
    "    drops = []\n",
    "    if file in [\"turmas\", \"gestor\", \"matricula\"]:\n",
    "        drops.extend(['TP_REGULAMENTACAO',\n",
    "                     'CO_UF',\n",
    "                     'IN_MANT_ESCOLA_PRIVADA_ONG',\n",
    "                     'NU_ANO_CENSO',\n",
    "                     'CO_MUNICIPIO',\n",
    "                     'IN_CONVENIADA_PP',\n",
    "                     'IN_ESPECIAL_EXCLUSIVA',\n",
    "                     'TP_CATEGORIA_ESCOLA_PRIVADA',\n",
    "                     'IN_MANT_ESCOLA_PRIVADA_OSCIP',\n",
    "                     'IN_MANT_ESCOLA_PRIV_ONG_OSCIP',\n",
    "                     'IN_MANT_ESCOLA_PRIVADA_S_FINS',\n",
    "                     'IN_MANT_ESCOLA_PRIVADA_SIST_S',\n",
    "                     'CO_DISTRITO',\n",
    "                     'IN_EDUCACAO_INDIGENA',\n",
    "                     'CO_MICRORREGIAO',\n",
    "                     'TP_DEPENDENCIA',\n",
    "                     'IN_EJA',\n",
    "                     'IN_REGULAR',\n",
    "                     'IN_PROFISSIONALIZANTE',\n",
    "                     'TP_LOCALIZACAO_DIFERENCIADA',\n",
    "                     'TP_CONVENIO_PODER_PUBLICO',\n",
    "                     'TP_LOCALIZACAO',\n",
    "                     'CO_REGIAO',\n",
    "                     'CO_MESORREGIAO',\n",
    "                     'IN_MANT_ESCOLA_PRIVADA_EMP',\n",
    "                     'IN_MANT_ESCOLA_PRIVADA_SIND',\n",
    "                    ]\n",
    "                )\n",
    "        \n",
    "    if file == 'matricula':\n",
    "        drops.extend([ 'NU_DIAS_ATIVIDADE', \n",
    "                         'NU_DURACAO_TURMA'])\n",
    "        \n",
    "    if file != \"turmas\":\n",
    "        drops.extend([\"TP_MEDIACAO_DIDATICO_PEDAGO\", \n",
    "                      \"TP_TIPO_ATENDIMENTO_TURMA\",\n",
    "                      \"TP_TIPO_LOCAL_TURMA\"])\n",
    "    \n",
    "        \n",
    "    df = df.drop(*drops)\n",
    "\n",
    "    return df\n",
    "        \n",
    "\n",
    "def transform(file, bucket, year, region=None):\n",
    "        df = load_csv(file, bucket, year, region)\n",
    "        df = drop_columns(df, file)\n",
    "        df = transform_string_columns(df, file, bucket)\n",
    "        df = transform_boolean_columns(df)\n",
    "        df = transform_integer_columns(df)\n",
    "        df = transform_date_columns(df, bucket)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17322978-c7ac-4ed5-98ae-567c64a991cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regions =  [\"co\", \"nordeste\", \"norte\", \"sudeste\", \"sul\"]\n",
    "regions =  [\"norte\"]\n",
    "if __name__ == \"__main__\":\n",
    "    if sys.argv[4:]:\n",
    "        bucket, year = sys.argv[4:]\n",
    "    else:\n",
    "        bucket = \"rjr-portal-da-transparencia\"\n",
    "        year = \"2020\"\n",
    "    escolas = transform(\"escolas\", bucket, year)\n",
    "    escolas = add_prefix_in_columns(escolas, \"E\")\n",
    "    turmas =  transform(\"turmas\", bucket, year)\n",
    "    turmas = add_prefix_in_columns(turmas, \"T\")\n",
    "    for region in regions:\n",
    "        matriculas = transform(\"matricula\", bucket, year, region)\n",
    "        matriculas = add_prefix_in_columns(matriculas, \"M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da562df5-94fb-49ad-aef2-f7d5775840b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "escolas_turmas = escolas.join(turmas, escolas.E_CO_ENTIDADE == turmas.T_CO_ENTIDADE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "613bb444",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriculas_turmas_escolas = matriculas.join(escolas_turmas, \n",
    "                                            matriculas.M_ID_TURMA == escolas_turmas.T_ID_TURMA\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4643a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = [\"E_NU_ANO_CENSO\", \"E_CO_REGIAO\", \"E_CO_UF\", \n",
    "              \"E_CO_MESORREGIAO\", \"E_CO_MICRORREGIAO\", \n",
    "              \"E_CO_MUNICIPIO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc85c4c3-98f1-447b-a6a0-404818f29a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/07/27 01:37:36 WARN org.apache.spark.sql.catalyst.util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "21/07/27 01:39:38 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 1560.5 KiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "matriculas_turmas_escolas \\\n",
    " .write \\\n",
    " .partitionBy(partitions) \\\n",
    " .parquet(f\"gs://{bucket}/processing_zone/censo-escolar\", compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed4d408-66ea-4a25-b00b-825660448dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0a73637a-9546-48a8-8c07-efee213e692e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# if FILE == \"matricula\":\n",
    "#     file =  f\"{FILE}_{REGION}\"\n",
    "# else:\n",
    "#     file = FILE\n",
    "    \n",
    "# df.write.parquet(f\"gs://{BUCKET}/temp/censo-escolar/{YEAR}/{FILE}.parquet\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "22aa55f7-492e-489b-ba53-b98aa9c8dbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = spark \\\n",
    "#         .read \\\n",
    "#         .parquet(f\"gs://{BUCKET}/temp/censo-escolar/{YEAR}/{FILE}.parquet\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1da958-d3e1-48a6-89fe-cf76c745cfca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}